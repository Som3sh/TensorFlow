{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2 quickstart for beginners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short introduction uses Keras to:\n",
    "\n",
    "- Load a prebuilt dataset.\n",
    "\n",
    "- Build a neural network machine learning model that classifies images.\n",
    "\n",
    "- Train this neural network.\n",
    "\n",
    "- Evaluate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"TensorFlow version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train , y_train) ,(x_test , y_test) = mnist.load_data()\n",
    "\n",
    "x_train , x_test = x_train / 255.0 , x_test / 255.0 # we divide by 255 as the pixel values range from 0 to 255 so we convert it to 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/someone./Library/Python/3.9/lib/python/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# building a tf.keras.Sequential Model :\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation for the above model**\n",
    "\n",
    "This code snippet defines a neural network model using TensorFlow's Keras API. Here's a step-by-step explanation:\n",
    "\n",
    "1. **Sequential Model Creation**: [`tf.keras.Sequential`](command:_github.copilot.openSymbolFromReferences?%5B%7B%22%24mid%22%3A1%2C%22path%22%3A%22%2FUsers%2Fsomeone.%2FLibrary%2FPython%2F3.9%2Flib%2Fpython%2Fsite-packages%2Ftensorflow%2F__init__.py%22%2C%22scheme%22%3A%22file%22%7D%2C%7B%22line%22%3A0%2C%22character%22%3A0%7D%5D \"../../../../../Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py\") is used to instantiate a linear stack of layers. This means that you're creating a model where the output of one layer is the input to the next layer.\n",
    "\n",
    "2. **Flatten Layer**: The first layer in the model is a `Flatten` layer with an `input_shape` of `(28,28)`. This layer transforms the input 2D image data (28x28 pixels) into a 1D array of 784 pixels (28*28). This is necessary because the next layer, a dense layer, requires a 1D input.\n",
    "\n",
    "3. **Dense Layer with ReLU Activation**: The next layer is a `Dense` layer with 128 neurons (or units). The activation function used is 'ReLU' (Rectified Linear Unit). This layer takes the flattened input and applies a linear transformation followed by the ReLU activation function. The ReLU function is commonly used to introduce non-linearity to the model, allowing it to learn more complex patterns.\n",
    "\n",
    "4. **Dropout Layer**: After the dense layer, a `Dropout` layer is added with a rate of 0.2. This means 20% of the neurons' outputs are randomly set to zero during training. Dropout is a regularization technique used to prevent overfitting by reducing the model's dependency on any single neuron.\n",
    "\n",
    "5. **Output Dense Layer**: The final layer is another `Dense` layer with 10 neurons. Since there's no activation function specified, it defaults to a linear activation. This layer is typically used for the output layer in a classification problem where the model predicts among 10 different classes.\n",
    "\n",
    "In summary, this model takes 28x28 pixel images as input, flattens the images, processes them through a dense layer with ReLU activation, applies dropout for regularization, and finally outputs a prediction through a dense layer with 10 units corresponding to the model's predictions for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
